{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Морфологическая дизамбигуация.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwUs5DLH2gEf",
        "colab_type": "text"
      },
      "source": [
        "## Морфологическая  дизамбигуация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25XVpdE42gEh",
        "colab_type": "text"
      },
      "source": [
        "Неоднозначность - одно из тех, свойств языка, которые делают его трудным (как для человеков так и для компьютеров.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFXO9iU2gEi",
        "colab_type": "text"
      },
      "source": [
        "Неоднозначность проявляется на разных уровнях языка. И под каждую есть своя задача в NLP.  \n",
        "Морфологическая неоднозначность - это когда одна и та же форма слова может иметь несколько вариантов морфологического описания.  \n",
        "Например, ``стали`` - может быть глаголом в прошедшем времени мн.ч 3.л (``они стали``), а может - существительным женского рода в родительном падеже (``коробка из стали``)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI04sUrx2gEj",
        "colab_type": "text"
      },
      "source": [
        "Скорее всего, вы уже знаете или догадываетесь, что неоднозначность снимается в контексте.   \n",
        "Однако контекст это не всегда несколько слов по соседству (как в примерах выше).   \n",
        "Иногда это контекст находится в других, необязательно соседних предложениях.   \n",
        "Например, предложение: ``Эти типы стали есть на складе.`` многозначно без другого предложения, в котором говорится о чём речь (о стали, или о типах).\n",
        "\n",
        "Поэтому в теории - это очень сложная задача. И над ней работают многие комп. лингвисты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-s7K6412gEk",
        "colab_type": "text"
      },
      "source": [
        "Однако на практике эта задача либо вообще не стоит, либо решается достаточно хорошо."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uflhsA732gEk",
        "colab_type": "text"
      },
      "source": [
        "Давайте посмотрим, почему:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfj4nHs52gEl",
        "colab_type": "text"
      },
      "source": [
        "Для русского есть готовые инструменты - pymorphy и mystem. И тот и другой умеют выдавать грамматическую информацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rothBuIA2gEl",
        "colab_type": "code",
        "outputId": "7584251e-059f-4696-e39f-a8dc7f92b1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "from lxml import etree\n",
        "!pip install pymorphy2[fast]\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.1MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2[fast])\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2[fast])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\" (from pymorphy2[fast])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c0/d8d967bcaa0b572f9dc1d878bbf5a7bfd5afa2102a5ae426731f6ce3bc26/DAWG-0.7.8.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 54.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/88/d0/4e4abc83eb8f59a71e8dbd8ba99fd5615a3af1fac1ef7f8825\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.7.8 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Sik0Y62gEp",
        "colab_type": "text"
      },
      "source": [
        "Чтобы оценить как они справляются с неоднозначностью нам нужен размеченный корпус. А точнее корпус-снятник (т.е. тот в котором вручную разрешена неоднозначность). Обычно для этого используют НКРЯ, но там нужно запрашивать и подписывать какое-то соглашение. Поэтому мы возьмем OpenCorpora, который можно скачать без этих сложностей вот тут - http://opencorpora.org/?page=downloads (нужен снятник без UNK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TO5NDDI2gEp",
        "colab_type": "text"
      },
      "source": [
        "Сам корпус в xml. Для того, чтобы достать все в питоновские структуры данных, удобно использовать lxml и xpath."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lP9zIqq2gEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "open_corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OZ9d8II2gEs",
        "colab_type": "text"
      },
      "source": [
        "Так достанутся все предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9w4UuL72gEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# document root + all tokens\n",
        "sentences = open_corpora.xpath('//tokens')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11P_6syx6Evw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.dom.minidom\n",
        "\n",
        "dom = xml.dom.minidom.parse('annot.opcorpora.no_ambig_strict.xml')\n",
        "pretty_xml_as_string = dom.toprettyxml()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA68cWxZ7scn",
        "colab_type": "code",
        "outputId": "5f5042b4-5549-41c5-9ebb-67bb5a66e848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1989
        }
      },
      "source": [
        "print(pretty_xml_as_string[750:3000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "agraphs>\n",
            "\t\t\t\n",
            "      \n",
            "\t\t\t<paragraph id=\"1\">\n",
            "\t\t\t\t\n",
            "        \n",
            "\t\t\t\t<sentence id=\"1\">\n",
            "\t\t\t\t\t\n",
            "          \n",
            "\t\t\t\t\t<source>«Школа злословия» учит прикусить язык</source>\n",
            "\t\t\t\t\t\n",
            "          \n",
            "\t\t\t\t\t<tokens>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"1\" text=\"«\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"2420236\" t=\"«\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"0\" t=\"«\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"PNCT\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"2\" text=\"Школа\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"834910\" t=\"Школа\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"380220\" t=\"школа\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"NOUN\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"inan\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"femn\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"sing\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"nomn\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"3\" text=\"злословия\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"2632816\" t=\"злословия\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"115766\" t=\"злословие\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"NOUN\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"inan\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"neut\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"sing\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"gent\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"4\" text=\"»\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"2420237\" t=\"»\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"0\" t=\"»\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"PNCT\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"5\" text=\"учит\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"834913\" t=\"учит\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"363313\" t=\"учу\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"VERB\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"impf\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"tran\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"sing\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"3per\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"pres\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"indc\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"6\" text=\"прикусить\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"834914\" t=\"прикусить\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"271426\" t=\"прикусить\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"INFN\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"perf\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"tran\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "            \n",
            "\t\t\t\t\t\t<token id=\"7\" text=\"язык\">\n",
            "\t\t\t\t\t\t\t<tfr rev_id=\"3408577\" t=\"язык\">\n",
            "\t\t\t\t\t\t\t\t<v>\n",
            "\t\t\t\t\t\t\t\t\t<l id=\"387573\" t=\"язык\">\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"NOUN\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"inan\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"masc\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"sing\"/>\n",
            "\t\t\t\t\t\t\t\t\t\t<g v=\"accs\"/>\n",
            "\t\t\t\t\t\t\t\t\t</l>\n",
            "\t\t\t\t\t\t\t\t</v>\n",
            "\t\t\t\t\t\t\t</tfr>\n",
            "\t\t\t\t\t\t</token>\n",
            "\t\t\t\t\t\t\n",
            "          \n",
            "\t\t\t\t\t</tokens>\n",
            "\t\t\t\t\t\n",
            "        \n",
            "\t\t\t\t</sen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxlTaCdF2gEu",
        "colab_type": "text"
      },
      "source": [
        "А так в отдельном предложении достанутся все слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1US78CO2gEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all tokens\n",
        "tokens = sentences[0].xpath('token')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgl2nH-i2gEx",
        "colab_type": "text"
      },
      "source": [
        "Для токена форма слова достается вот так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DDd8zh-2gEx",
        "colab_type": "code",
        "outputId": "76bbbbcd-f104-47d9-8b17-4886b1ed0370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# get attribute value\n",
        "tokens[0].xpath('@text')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['«']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqKzLcCH2gE1",
        "colab_type": "text"
      },
      "source": [
        "А грамматическая информация вот так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20GDV2ZC2gE2",
        "colab_type": "code",
        "outputId": "d6832cef-ba2c-4b64-9a23-a3096c6e1f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# full path or just all @v attributes\n",
        "tokens[1].xpath('tfr/v/l/g/@v'), tokens[1].xpath('.//@v')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['NOUN', 'inan', 'femn', 'sing', 'nomn'],\n",
              " ['NOUN', 'inan', 'femn', 'sing', 'nomn'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1ZhYLG2gE5",
        "colab_type": "text"
      },
      "source": [
        "Соберем весь корпус в список. Для начала будем смотреть только на часть речи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipt0kG_P2gE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in open_corpora.xpath('//tokens'):\n",
        "    sent_tagged = []\n",
        "    for token in sentence.xpath('token'):\n",
        "        word = token.xpath('@text')\n",
        "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
        "        sent_tagged.append((word[0], gram_info[0])) # word and POS\n",
        "    corpus.append(sent_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tKb43432gE8",
        "colab_type": "code",
        "outputId": "2bf630de-f36f-4d50-f7b8-aabdcc48c58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A3SLDuK2gE-",
        "colab_type": "code",
        "outputId": "91a41500-6654-4576-8fa9-f3bccfb391d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('«', 'PNCT'),\n",
              " ('Школа', 'NOUN'),\n",
              " ('злословия', 'NOUN'),\n",
              " ('»', 'PNCT'),\n",
              " ('учит', 'VERB'),\n",
              " ('прикусить', 'INFN'),\n",
              " ('язык', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQAvrp2E2gFA",
        "colab_type": "text"
      },
      "source": [
        "Воспользуемся pymorphy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M1WfLSk2gFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj9w-ILk_Klg",
        "colab_type": "code",
        "outputId": "55069101-62eb-4d05-e820-5f3ddf74b595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "morph.parse('слово')[0].tag.POS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3dJ7p2g2gFF",
        "colab_type": "text"
      },
      "source": [
        "Теперь просто пройдемся по каждому слову, предскажем его часть речи через пайморфи и сравним с тем, что стоит в корпусе. Если совпадает добавим в список 1, если нет 0. Усреднив нули и единицы получим accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYMSMgs2gFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "mistakes = Counter()\n",
        "\n",
        "for sent in corpus:\n",
        "    for word, tag in sent:\n",
        "        pred = str(morph.parse(word)[0].tag).split(',')[0].split(' ')[0] # in order to get PNCT as POS in case of punctuation\n",
        "        preds.append(int(pred == tag))\n",
        "        if not preds[-1]:\n",
        "            mistakes.update([(word, tag, pred)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GVdQ4yV2gFI",
        "colab_type": "text"
      },
      "source": [
        "Видно, что для части речи проблема неоднозначности особо и незаметна."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TieOv-f52gFK",
        "colab_type": "code",
        "outputId": "7289b416-34b9-4fef-989f-d0791e0b0559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9829557744163578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUJsIryJ2gFP",
        "colab_type": "text"
      },
      "source": [
        "А если посмотреть на ошибки, то видно, что они происходят в каких-то не очень значимых случаях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iNCvnQaN2gFQ",
        "colab_type": "code",
        "outputId": "14ca7851-d017-482d-e7c0-cacd3a34859b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        " mistakes.most_common(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('также', 'PRCL', 'CONJ'), 90),\n",
              " (('тоже', 'PRCL', 'ADVB'), 37),\n",
              " (('этом', 'ADJF', 'NPRO'), 36),\n",
              " (('Также', 'PRCL', 'CONJ'), 24),\n",
              " (('=', 'SYMB', 'UNKN'), 20)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hED4Ezzs2gFT",
        "colab_type": "text"
      },
      "source": [
        "Попробуем теперь предсказывать сразу всю грамматическую информацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKg9JNa62gFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in open_corpora.xpath('//tokens'):\n",
        "    sent_tagged = []\n",
        "    for token in sentence.xpath('token'):\n",
        "        word = token.xpath('@text')\n",
        "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
        "        sent_tagged.append((word[0], set(gram_info)))\n",
        "\n",
        "    corpus.append(sent_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcDBsWds2gFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = []\n",
        "mistakes = Counter()\n",
        "\n",
        "for sent in corpus:\n",
        "    for word, tag in sent:\n",
        "        pred = set(str(morph.parse(word)[0].tag).replace(' ', ',').split(','))\n",
        "        preds.append(len(pred & tag) / len(pred | tag))\n",
        "        if preds[-1] < 0.5:\n",
        "            mistakes.update([(word, tuple(tag), tuple(pred))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmILFsvI2gFW",
        "colab_type": "text"
      },
      "source": [
        "Оценивание правда придется поменять. Так как тэгов несколько и они могут быть в разном порядке мы не можем просто их склеить. Поэтому посчитаем меру жаккара между множествами тэгов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPJ-eWmm2gFX",
        "colab_type": "code",
        "outputId": "fb5995d7-9a94-411d-ae6f-6bceb774d246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(preds), np.std(preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9335980953841342, 0.18528548605606146)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC6eN0Zz2gFa",
        "colab_type": "text"
      },
      "source": [
        "Она достаточно высокая."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsOFGMua2gFb",
        "colab_type": "text"
      },
      "source": [
        "А ошибки все те же."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUktvNYs2gFb",
        "colab_type": "code",
        "outputId": "a3b8e07d-b5c6-488e-a415-f8723d6b2bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "mistakes.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('также', ('PRCL',), ('CONJ',)), 90),\n",
              " (('тоже', ('PRCL',), ('ADVB',)), 37),\n",
              " (('человек',\n",
              "   ('gent', 'masc', 'NOUN', 'anim', 'plur'),\n",
              "   ('sing', 'nomn', 'masc', 'NOUN', 'anim')),\n",
              "  34),\n",
              " (('этом',\n",
              "   ('loct', 'sing', 'Subx', 'ADJF', 'masc', 'Anph', 'Apro'),\n",
              "   ('loct', 'neut', 'NPRO', 'sing')),\n",
              "  27),\n",
              " (('Ссылки',\n",
              "   ('femn', 'nomn', 'inan', 'NOUN', 'plur'),\n",
              "   ('femn', 'sing', 'gent', 'inan', 'NOUN')),\n",
              "  26),\n",
              " (('Также', ('PRCL',), ('CONJ',)), 24),\n",
              " (('Примечания',\n",
              "   ('nomn', 'inan', 'neut', 'NOUN', 'plur'),\n",
              "   ('sing', 'gent', 'inan', 'neut', 'NOUN')),\n",
              "  23),\n",
              " (('=', ('SYMB',), ('UNKN',)), 20),\n",
              " (('№', ('SYMB',), ('UNKN',)), 19),\n",
              " (('>', ('SYMB',), ('UNKN',)), 19)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8yD1j9r2gFd",
        "colab_type": "text"
      },
      "source": [
        "Поэтому на практике, можно забить на неоднозначность."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZjMD80I2gFd",
        "colab_type": "text"
      },
      "source": [
        "Если все таки нужно (или хочется) разрешить неоднозначность - можно использовать mystem (там есть дизамбигуация). Но там своя токенизация и сложно будет оценивать качество на уже токенизированном корпусе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxLW7T632gFe",
        "colab_type": "text"
      },
      "source": [
        "Либо воспользоваться готовыми иструментами и обучить свой сниматель неоднозначности..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjFtouIS2gFe",
        "colab_type": "text"
      },
      "source": [
        "Про это лучше рассказать в колабе - https://colab.research.google.com/drive/1uTLlHbYdh8XA2Pbe7YAivS82FciLjU1b"
      ]
    }
  ]
}